<?xml version="1.0" ?>
<net name="mozilla-deepspeech-0.8.2" version="10">
	<layers>
		<layer id="0" name="input_node" type="Parameter" version="opset1">
			<data element_type="f32" shape="1,16,19,26"/>
			<output>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>19</dim>
					<dim>26</dim>
				</port>
			</output>
		</layer>
		<layer id="1" name="transpose/Cast_11895_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="4" size="32"/>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="2" name="transpose" type="Transpose" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>19</dim>
					<dim>26</dim>
				</port>
				<port id="1">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>16</dim>
					<dim>1</dim>
					<dim>19</dim>
					<dim>26</dim>
				</port>
			</output>
		</layer>
		<layer id="3" name="layer_1/weights/read/MinusOne1350_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="4" name="MatMul/1_port_transpose1301_const" type="Const" version="opset1">
			<data element_type="f32" offset="40" shape="2048,494" size="4046848"/>
			<output>
				<port id="1" precision="FP32">
					<dim>2048</dim>
					<dim>494</dim>
				</port>
			</output>
		</layer>
		<layer id="5" name="layer_1/weights/read/Shape" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>2048</dim>
					<dim>494</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="6" name="layer_1/weights/read/Shape/Gather/Cast_11885_const" type="Const" version="opset1">
			<data element_type="i32" offset="4046888" shape="1" size="4"/>
			<output>
				<port id="1" precision="I32">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="7" name="layer_1/weights/read/Shape/Gather/Cast_21887_const" type="Const" version="opset1">
			<data element_type="i64" offset="4046892" shape="" size="8"/>
			<output>
				<port id="1" precision="I64"/>
			</output>
		</layer>
		<layer id="8" name="layer_1/weights/read/Shape/Gather" type="Gather" version="opset1">
			<input>
				<port id="0">
					<dim>2</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="9" name="layer_1/weights/read/MinusOne/shapes_concat" type="Concat" version="opset1">
			<data axis="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="10" name="Reshape_1" type="Reshape" version="opset1">
			<data special_zero="False"/>
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>1</dim>
					<dim>19</dim>
					<dim>26</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>16</dim>
					<dim>494</dim>
				</port>
			</output>
		</layer>
		<layer id="11" name="MatMul" type="MatMul" version="opset1">
			<data transpose_a="False" transpose_b="True"/>
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>494</dim>
				</port>
				<port id="1">
					<dim>2048</dim>
					<dim>494</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="12" name="layer_1/bias/read/EltwiseUnsqueeze973_const" type="Const" version="opset1">
			<data element_type="f32" offset="4046900" shape="1,2048" size="8192"/>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="13" name="BiasAdd/Add" type="Add" version="opset1">
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>2048</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="14" name="Relu" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="15" name="Minimum/y/EltwiseUnsqueeze953_const" type="Const" version="opset1">
			<data element_type="f32" offset="4055092" shape="1,1" size="4"/>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="16" name="Minimum" type="Minimum" version="opset1">
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="17" name="MatMul_1/1_port_transpose1309_const" type="Const" version="opset1">
			<data element_type="f32" offset="4055096" shape="2048,2048" size="16777216"/>
			<output>
				<port id="1" precision="FP32">
					<dim>2048</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="18" name="MatMul_1" type="MatMul" version="opset1">
			<data transpose_a="False" transpose_b="True"/>
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
				<port id="1">
					<dim>2048</dim>
					<dim>2048</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="19" name="layer_2/bias/read/EltwiseUnsqueeze985_const" type="Const" version="opset1">
			<data element_type="f32" offset="20832312" shape="1,2048" size="8192"/>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="20" name="BiasAdd_1/Add" type="Add" version="opset1">
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>2048</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="21" name="Relu_1" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="22" name="Minimum_1/y/EltwiseUnsqueeze957_const" type="Const" version="opset1">
			<data element_type="f32" offset="4055092" shape="1,1" size="4"/>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="23" name="Minimum_1" type="Minimum" version="opset1">
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="24" name="MatMul_2/1_port_transpose1305_const" type="Const" version="opset1">
			<data element_type="f32" offset="20840504" shape="2048,2048" size="16777216"/>
			<output>
				<port id="1" precision="FP32">
					<dim>2048</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="25" name="MatMul_2" type="MatMul" version="opset1">
			<data transpose_a="False" transpose_b="True"/>
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
				<port id="1">
					<dim>2048</dim>
					<dim>2048</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="26" name="layer_3/bias/read/EltwiseUnsqueeze969_const" type="Const" version="opset1">
			<data element_type="f32" offset="37617720" shape="1,2048" size="8192"/>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="27" name="BiasAdd_2/Add" type="Add" version="opset1">
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>2048</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="28" name="Relu_2" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="29" name="Minimum_2/y/EltwiseUnsqueeze961_const" type="Const" version="opset1">
			<data element_type="f32" offset="4055092" shape="1,1" size="4"/>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="30" name="Minimum_2" type="Minimum" version="opset1">
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="31" name="Reshape_2/Cast_11891_const" type="Const" version="opset1">
			<data element_type="i64" offset="37625912" shape="3" size="24"/>
			<output>
				<port id="1" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="32" name="Reshape_2" type="Reshape" version="opset1">
			<data special_zero="False"/>
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
				<port id="1">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>16</dim>
					<dim>1</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="33" name="previous_state_h" type="Parameter" version="opset1">
			<data element_type="f32" shape="1,2048"/>
			<output>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="34" name="previous_state_c" type="Parameter" version="opset1">
			<data element_type="f32" shape="1,2048"/>
			<output>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="35" name="cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/BlockLSTM/TensorIterator" type="TensorIterator" version="opset1">
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>1</dim>
					<dim>2048</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>2048</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>2048</dim>
				</port>
			</input>
			<output>
				<port id="3" precision="FP32">
					<dim>16</dim>
					<dim>1</dim>
					<dim>2048</dim>
				</port>
				<port id="4" precision="FP32">
					<dim>1</dim>
					<dim>2048</dim>
				</port>
				<port id="5" precision="FP32">
					<dim>1</dim>
					<dim>2048</dim>
				</port>
			</output>
			<port_map>
				<input axis="0" external_port_id="0" internal_layer_id="0" part_size="1" stride="1"/>
				<input external_port_id="1" internal_layer_id="3"/>
				<input external_port_id="2" internal_layer_id="4"/>
				<output axis="0" external_port_id="3" internal_layer_id="13" part_size="1" stride="1"/>
				<output external_port_id="4" internal_layer_id="9"/>
				<output external_port_id="5" internal_layer_id="10"/>
			</port_map>
			<back_edges>
				<edge from-layer="10" to-layer="4"/>
				<edge from-layer="9" to-layer="3"/>
			</back_edges>
			<body>
				<layers>
					<layer id="0" name="20" type="Parameter" version="opset1">
						<data element_type="f32" shape="1,1,2048"/>
						<output>
							<port id="0" precision="FP32">
								<dim>1</dim>
								<dim>1</dim>
								<dim>2048</dim>
							</port>
						</output>
					</layer>
					<layer id="1" name="7_const" type="Const" version="opset1">
						<data element_type="i64" offset="4046892" shape="1" size="8"/>
						<output>
							<port id="1" precision="I64">
								<dim>1</dim>
							</port>
						</output>
					</layer>
					<layer id="2" name="cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/BlockLSTM/input_squeeze" type="Squeeze" version="opset1">
						<input>
							<port id="0">
								<dim>1</dim>
								<dim>1</dim>
								<dim>2048</dim>
							</port>
							<port id="1">
								<dim>1</dim>
							</port>
						</input>
						<output>
							<port id="2" precision="FP32">
								<dim>1</dim>
								<dim>2048</dim>
							</port>
						</output>
					</layer>
					<layer id="3" name="22" type="Parameter" version="opset1">
						<data element_type="f32" shape="1,2048"/>
						<output>
							<port id="0" precision="FP32">
								<dim>1</dim>
								<dim>2048</dim>
							</port>
						</output>
					</layer>
					<layer id="4" name="24" type="Parameter" version="opset1">
						<data element_type="f32" shape="1,2048"/>
						<output>
							<port id="0" precision="FP32">
								<dim>1</dim>
								<dim>2048</dim>
							</port>
						</output>
					</layer>
					<layer id="5" name="cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/BlockLSTM/LSTMCell/Split201_const" type="Const" version="opset1">
						<data element_type="f32" offset="54649052" shape="8192,2048" size="67108864"/>
						<output>
							<port id="1" precision="FP32">
								<dim>8192</dim>
								<dim>2048</dim>
							</port>
						</output>
					</layer>
					<layer id="6" name="cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/BlockLSTM/LSTMCell/Split202_const" type="Const" version="opset1">
						<data element_type="f32" offset="121757916" shape="8192,2048" size="67108864"/>
						<output>
							<port id="1" precision="FP32">
								<dim>8192</dim>
								<dim>2048</dim>
							</port>
						</output>
					</layer>
					<layer id="7" name="cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/BlockLSTM/inport/2_const" type="Const" version="opset1">
						<data element_type="f32" offset="188866780" shape="8192" size="32768"/>
						<output>
							<port id="1" precision="FP32">
								<dim>8192</dim>
							</port>
						</output>
					</layer>
					<layer id="8" name="cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/BlockLSTM/LSTMCell" type="LSTMCell" version="opset4">
						<data hidden_size="2048"/>
						<input>
							<port id="0">
								<dim>1</dim>
								<dim>2048</dim>
							</port>
							<port id="1">
								<dim>1</dim>
								<dim>2048</dim>
							</port>
							<port id="2">
								<dim>1</dim>
								<dim>2048</dim>
							</port>
							<port id="3">
								<dim>8192</dim>
								<dim>2048</dim>
							</port>
							<port id="4">
								<dim>8192</dim>
								<dim>2048</dim>
							</port>
							<port id="5">
								<dim>8192</dim>
							</port>
						</input>
						<output>
							<port id="6" precision="FP32">
								<dim>1</dim>
								<dim>2048</dim>
							</port>
							<port id="7" precision="FP32">
								<dim>1</dim>
								<dim>2048</dim>
							</port>
						</output>
					</layer>
					<layer id="9" name="cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/BlockLSTM/outport/0/sink_port_0" type="Result" version="opset1">
						<input>
							<port id="0">
								<dim>1</dim>
								<dim>2048</dim>
							</port>
						</input>
					</layer>
					<layer id="10" name="cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/BlockLSTM/outport/1/sink_port_0" type="Result" version="opset1">
						<input>
							<port id="0">
								<dim>1</dim>
								<dim>2048</dim>
							</port>
						</input>
					</layer>
					<layer id="11" name="15_const" type="Const" version="opset1">
						<data element_type="i64" offset="4046892" shape="1" size="8"/>
						<output>
							<port id="1" precision="I64">
								<dim>1</dim>
							</port>
						</output>
					</layer>
					<layer id="12" name="cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/BlockLSTMoutput_unsqueeze" type="Unsqueeze" version="opset1">
						<input>
							<port id="0">
								<dim>1</dim>
								<dim>2048</dim>
							</port>
							<port id="1">
								<dim>1</dim>
							</port>
						</input>
						<output>
							<port id="2" precision="FP32">
								<dim>1</dim>
								<dim>1</dim>
								<dim>2048</dim>
							</port>
						</output>
					</layer>
					<layer id="13" name="18/sink_port_0" type="Result" version="opset1">
						<input>
							<port id="0">
								<dim>1</dim>
								<dim>1</dim>
								<dim>2048</dim>
							</port>
						</input>
					</layer>
				</layers>
				<edges>
					<edge from-layer="0" from-port="0" to-layer="2" to-port="0"/>
					<edge from-layer="1" from-port="1" to-layer="2" to-port="1"/>
					<edge from-layer="2" from-port="2" to-layer="8" to-port="0"/>
					<edge from-layer="3" from-port="0" to-layer="8" to-port="1"/>
					<edge from-layer="4" from-port="0" to-layer="8" to-port="2"/>
					<edge from-layer="5" from-port="1" to-layer="8" to-port="3"/>
					<edge from-layer="6" from-port="1" to-layer="8" to-port="4"/>
					<edge from-layer="7" from-port="1" to-layer="8" to-port="5"/>
					<edge from-layer="8" from-port="6" to-layer="9" to-port="0"/>
					<edge from-layer="8" from-port="7" to-layer="10" to-port="0"/>
					<edge from-layer="8" from-port="6" to-layer="12" to-port="0"/>
					<edge from-layer="11" from-port="1" to-layer="12" to-port="1"/>
					<edge from-layer="12" from-port="2" to-layer="13" to-port="0"/>
				</edges>
			</body>
		</layer>
		<layer id="36" name="cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/GatherNd/sink_port_0" type="Result" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>2048</dim>
				</port>
			</input>
		</layer>
		<layer id="37" name="cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/GatherNd_1/sink_port_0" type="Result" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>2048</dim>
				</port>
			</input>
		</layer>
		<layer id="38" name="layer_5/weights/read/MinusOne1338_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="39" name="MatMul_3/1_port_transpose1293_const" type="Const" version="opset1">
			<data element_type="f32" offset="37625936" shape="2048,2048" size="16777216"/>
			<output>
				<port id="1" precision="FP32">
					<dim>2048</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="40" name="layer_5/weights/read/Shape" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>2048</dim>
					<dim>2048</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="41" name="layer_5/weights/read/Shape/Gather/Cast_11897_const" type="Const" version="opset1">
			<data element_type="i32" offset="4046888" shape="1" size="4"/>
			<output>
				<port id="1" precision="I32">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="42" name="layer_5/weights/read/Shape/Gather/Cast_21899_const" type="Const" version="opset1">
			<data element_type="i64" offset="4046892" shape="" size="8"/>
			<output>
				<port id="1" precision="I64"/>
			</output>
		</layer>
		<layer id="43" name="layer_5/weights/read/Shape/Gather" type="Gather" version="opset1">
			<input>
				<port id="0">
					<dim>2</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="44" name="layer_5/weights/read/MinusOne/shapes_concat" type="Concat" version="opset1">
			<data axis="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="45" name="Reshape_3" type="Reshape" version="opset1">
			<data special_zero="False"/>
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>1</dim>
					<dim>2048</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="46" name="MatMul_3" type="MatMul" version="opset1">
			<data transpose_a="False" transpose_b="True"/>
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
				<port id="1">
					<dim>2048</dim>
					<dim>2048</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="47" name="layer_5/bias/read/EltwiseUnsqueeze977_const" type="Const" version="opset1">
			<data element_type="f32" offset="54403152" shape="1,2048" size="8192"/>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="48" name="BiasAdd_3/Add" type="Add" version="opset1">
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>2048</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="49" name="Relu_3" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="50" name="Minimum_3/y/EltwiseUnsqueeze965_const" type="Const" version="opset1">
			<data element_type="f32" offset="4055092" shape="1,1" size="4"/>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="51" name="Minimum_3" type="Minimum" version="opset1">
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="52" name="MatMul_4/1_port_transpose1297_const" type="Const" version="opset1">
			<data element_type="f32" offset="54411344" shape="29,2048" size="237568"/>
			<output>
				<port id="1" precision="FP32">
					<dim>29</dim>
					<dim>2048</dim>
				</port>
			</output>
		</layer>
		<layer id="53" name="MatMul_4" type="MatMul" version="opset1">
			<data transpose_a="False" transpose_b="True"/>
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>2048</dim>
				</port>
				<port id="1">
					<dim>29</dim>
					<dim>2048</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>16</dim>
					<dim>29</dim>
				</port>
			</output>
		</layer>
		<layer id="54" name="layer_6/bias/read/EltwiseUnsqueeze981_const" type="Const" version="opset1">
			<data element_type="f32" offset="54648912" shape="1,29" size="116"/>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>29</dim>
				</port>
			</output>
		</layer>
		<layer id="55" name="BiasAdd_4/Add" type="Add" version="opset1">
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>29</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>29</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>16</dim>
					<dim>29</dim>
				</port>
			</output>
		</layer>
		<layer id="56" name="raw_logits/Cast_11889_const" type="Const" version="opset1">
			<data element_type="i64" offset="54649028" shape="3" size="24"/>
			<output>
				<port id="1" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="57" name="raw_logits" type="Reshape" version="opset1">
			<data special_zero="False"/>
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>29</dim>
				</port>
				<port id="1">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>16</dim>
					<dim>1</dim>
					<dim>29</dim>
				</port>
			</output>
		</layer>
		<layer id="58" name="logits" type="SoftMax" version="opset1">
			<data axis="2"/>
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>1</dim>
					<dim>29</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>16</dim>
					<dim>1</dim>
					<dim>29</dim>
				</port>
			</output>
		</layer>
		<layer id="59" name="logits/sink_port_0" type="Result" version="opset1">
			<input>
				<port id="0">
					<dim>16</dim>
					<dim>1</dim>
					<dim>29</dim>
				</port>
			</input>
		</layer>
	</layers>
	<edges>
		<edge from-layer="0" from-port="0" to-layer="2" to-port="0"/>
		<edge from-layer="1" from-port="1" to-layer="2" to-port="1"/>
		<edge from-layer="4" from-port="1" to-layer="5" to-port="0"/>
		<edge from-layer="5" from-port="1" to-layer="8" to-port="0"/>
		<edge from-layer="6" from-port="1" to-layer="8" to-port="1"/>
		<edge from-layer="7" from-port="1" to-layer="8" to-port="2"/>
		<edge from-layer="3" from-port="1" to-layer="9" to-port="0"/>
		<edge from-layer="8" from-port="3" to-layer="9" to-port="1"/>
		<edge from-layer="2" from-port="2" to-layer="10" to-port="0"/>
		<edge from-layer="9" from-port="2" to-layer="10" to-port="1"/>
		<edge from-layer="10" from-port="2" to-layer="11" to-port="0"/>
		<edge from-layer="4" from-port="1" to-layer="11" to-port="1"/>
		<edge from-layer="11" from-port="2" to-layer="13" to-port="0"/>
		<edge from-layer="12" from-port="1" to-layer="13" to-port="1"/>
		<edge from-layer="13" from-port="2" to-layer="14" to-port="0"/>
		<edge from-layer="14" from-port="1" to-layer="16" to-port="0"/>
		<edge from-layer="15" from-port="1" to-layer="16" to-port="1"/>
		<edge from-layer="16" from-port="2" to-layer="18" to-port="0"/>
		<edge from-layer="17" from-port="1" to-layer="18" to-port="1"/>
		<edge from-layer="18" from-port="2" to-layer="20" to-port="0"/>
		<edge from-layer="19" from-port="1" to-layer="20" to-port="1"/>
		<edge from-layer="20" from-port="2" to-layer="21" to-port="0"/>
		<edge from-layer="21" from-port="1" to-layer="23" to-port="0"/>
		<edge from-layer="22" from-port="1" to-layer="23" to-port="1"/>
		<edge from-layer="23" from-port="2" to-layer="25" to-port="0"/>
		<edge from-layer="24" from-port="1" to-layer="25" to-port="1"/>
		<edge from-layer="25" from-port="2" to-layer="27" to-port="0"/>
		<edge from-layer="26" from-port="1" to-layer="27" to-port="1"/>
		<edge from-layer="27" from-port="2" to-layer="28" to-port="0"/>
		<edge from-layer="28" from-port="1" to-layer="30" to-port="0"/>
		<edge from-layer="29" from-port="1" to-layer="30" to-port="1"/>
		<edge from-layer="30" from-port="2" to-layer="32" to-port="0"/>
		<edge from-layer="31" from-port="1" to-layer="32" to-port="1"/>
		<edge from-layer="32" from-port="2" to-layer="35" to-port="0"/>
		<edge from-layer="33" from-port="0" to-layer="35" to-port="1"/>
		<edge from-layer="34" from-port="0" to-layer="35" to-port="2"/>
		<edge from-layer="35" from-port="5" to-layer="36" to-port="0"/>
		<edge from-layer="35" from-port="4" to-layer="37" to-port="0"/>
		<edge from-layer="39" from-port="1" to-layer="40" to-port="0"/>
		<edge from-layer="40" from-port="1" to-layer="43" to-port="0"/>
		<edge from-layer="41" from-port="1" to-layer="43" to-port="1"/>
		<edge from-layer="42" from-port="1" to-layer="43" to-port="2"/>
		<edge from-layer="38" from-port="1" to-layer="44" to-port="0"/>
		<edge from-layer="43" from-port="3" to-layer="44" to-port="1"/>
		<edge from-layer="35" from-port="3" to-layer="45" to-port="0"/>
		<edge from-layer="44" from-port="2" to-layer="45" to-port="1"/>
		<edge from-layer="45" from-port="2" to-layer="46" to-port="0"/>
		<edge from-layer="39" from-port="1" to-layer="46" to-port="1"/>
		<edge from-layer="46" from-port="2" to-layer="48" to-port="0"/>
		<edge from-layer="47" from-port="1" to-layer="48" to-port="1"/>
		<edge from-layer="48" from-port="2" to-layer="49" to-port="0"/>
		<edge from-layer="49" from-port="1" to-layer="51" to-port="0"/>
		<edge from-layer="50" from-port="1" to-layer="51" to-port="1"/>
		<edge from-layer="51" from-port="2" to-layer="53" to-port="0"/>
		<edge from-layer="52" from-port="1" to-layer="53" to-port="1"/>
		<edge from-layer="53" from-port="2" to-layer="55" to-port="0"/>
		<edge from-layer="54" from-port="1" to-layer="55" to-port="1"/>
		<edge from-layer="55" from-port="2" to-layer="57" to-port="0"/>
		<edge from-layer="56" from-port="1" to-layer="57" to-port="1"/>
		<edge from-layer="57" from-port="2" to-layer="58" to-port="0"/>
		<edge from-layer="58" from-port="1" to-layer="59" to-port="0"/>
	</edges>
	<meta_data>
		<MO_version value="2021.2.0-1877-176bdf51370-releases/2021/2"/>
		<cli_parameters>
			<caffe_parser_path value="DIR"/>
			<data_type value="FP32"/>
			<disable_nhwc_to_nchw value="True"/>
			<disable_omitting_optional value="False"/>
			<disable_resnet_optimization value="False"/>
			<disable_weights_compression value="False"/>
			<enable_concat_optimization value="False"/>
			<enable_flattening_nested_params value="False"/>
			<enable_ssd_gluoncv value="False"/>
			<extensions value="DIR"/>
			<framework value="tf"/>
			<freeze_placeholder_with_value value="{'input_lengths': ['16']}"/>
			<generate_deprecated_IR_V7 value="False"/>
			<input value="input_node,previous_state_h,previous_state_c"/>
			<input_model value="DIR/deepspeech-0.8.2-models.pb"/>
			<input_model_is_text value="False"/>
			<input_shape value="[1,16,19,26],[1,2048],[1,2048]"/>
			<k value="DIR/CustomLayersMapping.xml"/>
			<keep_shape_ops value="True"/>
			<legacy_mxnet_model value="False"/>
			<log_level value="ERROR"/>
			<mean_scale_values value="{}"/>
			<mean_values value="()"/>
			<model_name value="mozilla-deepspeech-0.8.2"/>
			<output value="['logits', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/GatherNd', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/GatherNd_1']"/>
			<output_dir value="DIR"/>
			<placeholder_data_types value="{}"/>
			<placeholder_shapes value="{'input_node': array([ 1, 16, 19, 26]), 'previous_state_h': array([   1, 2048]), 'previous_state_c': array([   1, 2048])}"/>
			<progress value="False"/>
			<remove_memory value="False"/>
			<remove_output_softmax value="False"/>
			<reverse_input_channels value="False"/>
			<save_params_from_nd value="False"/>
			<scale_values value="()"/>
			<silent value="False"/>
			<static_shape value="False"/>
			<stream_output value="False"/>
			<unset unset_cli_parameters="batch, counts, disable_fusing, disable_gfusing, finegrain_fusing, input_checkpoint, input_meta_graph, input_proto, input_symbol, mean_file, mean_file_offsets, move_to_preprocess, nd_prefix_name, pretrained_model_name, saved_model_dir, saved_model_tags, scale, tensorboard_logdir, tensorflow_custom_layer_libraries, tensorflow_custom_operations_config_update, tensorflow_object_detection_api_pipeline_config, tensorflow_use_custom_operations_config, transformations_config"/>
		</cli_parameters>
	</meta_data>
</net>
